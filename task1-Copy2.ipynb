{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import CSVLogger\n",
    "import LoadDataset as LD\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "from scipy.misc import imresize\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 6\n",
    "print(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset directory added\n",
      "['c6', 'c4', 'c5', 'c8', 'c1', 'c0', 'c7', 'c3', 'c9', 'c2']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/usr/local/lib/python3.6/dist-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c6  directory images are fetched!!! \n",
      "c4  directory images are fetched!!! \n",
      "c5  directory images are fetched!!! \n",
      "c8  directory images are fetched!!! \n",
      "c1  directory images are fetched!!! \n",
      "c0  directory images are fetched!!! \n",
      "c7  directory images are fetched!!! \n",
      "c3  directory images are fetched!!! \n",
      "c9  directory images are fetched!!! \n",
      "c2  directory images are fetched!!! \n"
     ]
    }
   ],
   "source": [
    "n_categories = 3\n",
    "categories = np.array([\"c0\", \"c1\"])\n",
    "\n",
    "load_data = LD.LoadData('/netscratch/data/state_farm/imgs/train') # give the directory address.\n",
    "X_dat ,Y_dat = load_data.generate_data()\n",
    "\n",
    "X_dat, Y_dat = load_data.shuffle_data(X_dat,Y_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227, 227, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dat[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22424, 227, 227, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X_dat)\n",
    "Y = np.array(Y_dat)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.09427444, 0.14525483, 0.11780385],\n",
       "        [0.09005317, 0.14103357, 0.11358259],\n",
       "        [0.10114227, 0.15212266, 0.12467168],\n",
       "        ...,\n",
       "        [0.84191137, 0.99703965, 0.86481437],\n",
       "        [0.85719327, 0.98088044, 0.90917564],\n",
       "        [0.91226964, 0.99761728, 0.98213568]],\n",
       "\n",
       "       [[0.0937635 , 0.14474389, 0.11729291],\n",
       "        [0.1061674 , 0.15714779, 0.12969681],\n",
       "        [0.09922882, 0.15020921, 0.12275823],\n",
       "        ...,\n",
       "        [0.46304942, 0.6242138 , 0.47761658],\n",
       "        [0.13655326, 0.22857291, 0.15548239],\n",
       "        [0.6518957 , 0.72247225, 0.69901029]],\n",
       "\n",
       "       [[0.10076877, 0.15174916, 0.12429818],\n",
       "        [0.10980392, 0.16078431, 0.13333333],\n",
       "        [0.10850652, 0.15948691, 0.13203593],\n",
       "        ...,\n",
       "        [0.37452537, 0.53341975, 0.38300426],\n",
       "        [0.002043  , 0.09703028, 0.00539447],\n",
       "        [0.03310631, 0.0946777 , 0.04624927]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.0238079 , 0.02772946, 0.00812162],\n",
       "        [0.0204433 , 0.02436486, 0.00475702],\n",
       "        [0.01876997, 0.02269154, 0.0030837 ],\n",
       "        ...,\n",
       "        [0.08638163, 0.08246006, 0.07461692],\n",
       "        [0.18257511, 0.18257511, 0.17473197],\n",
       "        [0.16500613, 0.16668187, 0.15800086]],\n",
       "\n",
       "       [[0.02224238, 0.02616395, 0.0065561 ],\n",
       "        [0.0186695 , 0.02259107, 0.00298322],\n",
       "        [0.01498039, 0.01890196, 0.        ],\n",
       "        ...,\n",
       "        [0.16233084, 0.15899043, 0.15114729],\n",
       "        [0.17545222, 0.17757712, 0.16867153],\n",
       "        [0.17156113, 0.17940427, 0.16763956]],\n",
       "\n",
       "       [[0.01960784, 0.02352941, 0.00392157],\n",
       "        [0.01568627, 0.01960784, 0.        ],\n",
       "        [0.01176471, 0.01568627, 0.        ],\n",
       "        ...,\n",
       "        [0.16523313, 0.16308232, 0.15523918],\n",
       "        [0.17740893, 0.18525207, 0.17348736],\n",
       "        [0.16990716, 0.17881275, 0.16669389]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(img, alpha_std=0.1):\n",
    "    orig_img = img.astype(float).copy()\n",
    "#     img = img / 255.0  # rescale to 0 to 1 range\n",
    "    # flatten image to columns of RGB\n",
    "    img_rs = img.reshape(-1, 3)\n",
    "    # img_rs shape (640000, 3)\n",
    "    img_centered = img_rs - np.mean(img_rs, axis=0)\n",
    "    # paper says 3x3 covariance matrix\n",
    "    img_cov = np.cov(img_centered, rowvar=False)\n",
    "    # eigen values and eigen vectors\n",
    "    eig_vals, eig_vecs = np.linalg.eigh(img_cov)\n",
    "    # sort values and vector\n",
    "    sort_perm = eig_vals[::-1].argsort()\n",
    "    eig_vals[::-1].sort()\n",
    "    eig_vecs = eig_vecs[:, sort_perm]\n",
    "\n",
    "    # get [p1, p2, p3]\n",
    "    m1 = np.column_stack((eig_vecs))\n",
    "\n",
    "    # get 3x1 matrix of eigen values multiplied by random variable draw from normal\n",
    "    # distribution with mean of 0 and standard deviation of 0.1\n",
    "    m2 = np.zeros((3, 1))\n",
    "    # according to the paper alpha should only be draw once per augmentation (not once per channel)\n",
    "    alpha = np.random.normal(0, alpha_std)\n",
    "\n",
    "    # broad cast to speed things up\n",
    "    m2[:, 0] = alpha * eig_vals[:]\n",
    "\n",
    "    # this is the vector that we're going to add to each pixel in a moment\n",
    "    add_vect = np.matrix(m1) * np.matrix(m2)\n",
    "\n",
    "    for idx in range(3):   # RGB\n",
    "        orig_img[..., idx] += add_vect[idx]\n",
    "    orig_img = np.clip(orig_img, 0.0, 255.0)\n",
    "    orig_img = orig_img.astype(np.uint8)\n",
    "    return orig_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227 227 3\n",
      "(20000, 227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train) = (X[0:20000], Y[0:20000])\n",
    "(x_test, y_test) = (X[20000:], Y[20000:])\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "print(img_height, img_width, channel)\n",
    "\n",
    "# x_train = pca(x_train)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.04705882, 0.05098039, 0.03137255],\n",
       "        [0.04705882, 0.05098039, 0.03137255],\n",
       "        [0.04705882, 0.05098039, 0.03137255],\n",
       "        ...,\n",
       "        [0.92358988, 1.        , 0.99904777],\n",
       "        [0.99714088, 0.99714088, 0.99154358],\n",
       "        [0.99537013, 1.        , 0.97611644]],\n",
       "\n",
       "       [[0.04705882, 0.05098039, 0.03137255],\n",
       "        [0.04705882, 0.05098039, 0.03137255],\n",
       "        [0.04705882, 0.05098039, 0.03137255],\n",
       "        ...,\n",
       "        [0.92358988, 1.        , 1.        ],\n",
       "        [0.99714088, 0.99642712, 0.99836428],\n",
       "        [0.99537013, 0.99724924, 0.98483123]],\n",
       "\n",
       "       [[0.04705882, 0.05098039, 0.03137255],\n",
       "        [0.04705882, 0.05098039, 0.03137255],\n",
       "        [0.04705882, 0.05098039, 0.03137255],\n",
       "        ...,\n",
       "        [0.92358988, 0.99860758, 1.        ],\n",
       "        [0.99714088, 0.99321931, 1.        ],\n",
       "        [0.99537013, 0.99607843, 0.99837816]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.03425343, 0.0356614 , 0.0505098 ],\n",
       "        [0.01621215, 0.03057062, 0.04663835],\n",
       "        [0.00281073, 0.03149519, 0.05595922],\n",
       "        ...,\n",
       "        [0.04610866, 0.03042239, 0.02650082],\n",
       "        [0.05753408, 0.0418478 , 0.03792624],\n",
       "        [0.05358037, 0.0378941 , 0.03397253]],\n",
       "\n",
       "       [[0.04642509, 0.02511483, 0.02014415],\n",
       "        [0.03901473, 0.02790015, 0.02959634],\n",
       "        [0.01961406, 0.02728928, 0.04036832],\n",
       "        ...,\n",
       "        [0.04953546, 0.03384919, 0.02992762],\n",
       "        [0.04369415, 0.02800787, 0.0240863 ],\n",
       "        [0.06637222, 0.05068595, 0.04676438]],\n",
       "\n",
       "       [[0.06318825, 0.02223636, 0.01439323],\n",
       "        [0.05494439, 0.02581767, 0.02116113],\n",
       "        [0.03950696, 0.03249305, 0.0376132 ],\n",
       "        ...,\n",
       "        [0.05767021, 0.04198394, 0.03806237],\n",
       "        [0.04607881, 0.03039254, 0.02647097],\n",
       "        [0.1331433 , 0.11745703, 0.11353546]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "# # for cifar10 dataset\n",
    "# # Load CIFAR10 Data\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "# print(x_train.shape)\n",
    "\n",
    "# img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n",
    "# # convert to one hot encoing\n",
    "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet Define the Model\n",
    "model = Sequential()\n",
    "# model.add(Conv2D(96, (11,11), strides=(4,4), activation='relu', padding='valid', input_shape=(img_height, img_width, channel,)))\n",
    "# for original Alexnet\n",
    "model.add(Conv2D(96, (3,3), strides=(2,2), activation='relu', padding='same', input_shape=(img_height, img_width, channel,)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "# Local Response normalization for Original Alexnet\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, (5,5), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "# Local Response normalization for Original Alexnet\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(38, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(38, (3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(25, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "# Local Response normalization for Original Alexnet\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 114, 114, 96)      2688      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 57, 57, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 57, 57, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 57, 57, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 38)        87590     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 28, 28, 38)        13034     \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 25)        8575      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 25)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 13, 13, 25)        100       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4225)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               422600    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 1,161,761\n",
      "Trainable params: 1,161,007\n",
      "Non-trainable params: 754\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 2424 samples\n",
      "Epoch 1/6\n",
      "20000/20000 [==============================] - 52s 3ms/step - loss: 2.2054 - acc: 0.1626 - val_loss: 1.8276 - val_acc: 0.3007\n",
      "Epoch 2/6\n",
      "20000/20000 [==============================] - 51s 3ms/step - loss: 1.7803 - acc: 0.3275 - val_loss: 1.4131 - val_acc: 0.5503\n",
      "Epoch 3/6\n",
      "20000/20000 [==============================] - 51s 3ms/step - loss: 1.4352 - acc: 0.4559 - val_loss: 0.9775 - val_acc: 0.6753\n",
      "Epoch 4/6\n",
      "20000/20000 [==============================] - 51s 3ms/step - loss: 1.1364 - acc: 0.5654 - val_loss: 0.9483 - val_acc: 0.7038\n",
      "Epoch 5/6\n",
      "20000/20000 [==============================] - 51s 3ms/step - loss: 0.8841 - acc: 0.6708 - val_loss: 0.4733 - val_acc: 0.8812\n",
      "Epoch 6/6\n",
      "20000/20000 [==============================] - 52s 3ms/step - loss: 0.6924 - acc: 0.7543 - val_loss: 0.3016 - val_acc: 0.9307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb42050e1d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# print the model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the Model\n",
    "\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=';')\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1, callbacks=[csv_logger],\n",
    "                    validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.30159104711348467\n",
      "Test accuracy: 0.9306930693069307\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
